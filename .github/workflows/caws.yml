name: CAWS Quality Gates
on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      risk: ${{ steps.risk.outputs.tier }}
      profile: ${{ steps.risk.outputs.profile }}
    steps:
      - uses: actions/checkout@v4
      - name: Parse Working Spec
        id: risk
        run: |
          pipx install yq
          yq -o=json '.caws/working-spec.yaml' > .caws/working-spec.json
          echo "tier=$(jq -r .risk_tier .caws/working-spec.json)" >> $GITHUB_OUTPUT
          echo "profile=$(jq -r .profile .caws/working-spec.json)" >> $GITHUB_OUTPUT
      - name: Bootstrap Environment
        run: make caws:bootstrap
      - name: Validate Spec
        run: tools/caws/validate .caws/working-spec.json

  static:
    needs: setup
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - run: make caws:static

  unit:
    needs: setup
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - run: make caws:unit
      - run: tools/caws/gates coverage --tier ${{ needs.setup.outputs.risk }}

  mutation:
    needs: unit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - run: make caws:mutation
      - run: tools/caws/gates mutation --tier ${{ needs.setup.outputs.risk }}

  contracts:
    needs: setup
    runs-on: ubuntu-latest
    if: needs.setup.outputs.profile == 'backend-api' || (needs.setup.outputs.profile == 'web-ui' && contains(github.event.pull_request.changed_files, 'contracts/'))
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - run: make caws:contracts
      - run: tools/caws/gates contracts --tier ${{ needs.setup.outputs.risk }}

  integration:
    needs: [setup]
    runs-on: ubuntu-latest
    if: needs.setup.outputs.profile == 'backend-api' || needs.setup.outputs.profile == 'web-ui'
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - run: make caws:integration

  visual-regression:
    needs: [integration]
    runs-on: ubuntu-latest
    if: needs.setup.outputs.profile == 'web-ui' && (github.event_name == 'pull_request')
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for baseline comparison

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      - name: Build application
        run: npm run build

      - name: Start application
        run: npm start &
        env:
          PORT: 3000

      - name: Wait for application to be ready
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:3000 > /dev/null 2>&1; do sleep 1; done'

      - name: Run visual regression tests
        run: npm run test:e2e
        env:
          CI: true
        continue-on-error: true  # Allow visual tests to fail without blocking PR

      - name: Upload visual regression results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: visual-regression-results
          path: |
            test-results/
            playwright-report/
          retention-days: 30

      - name: Comment on PR with visual regression results
        uses: actions/github-script@v7
        if: always()
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Check if visual regression tests passed
            const testResultsPath = 'test-results/e2e-results.json';
            let testResults = { passed: 0, failed: 0 };

            if (fs.existsSync(testResultsPath)) {
              try {
                const results = JSON.parse(fs.readFileSync(testResultsPath, 'utf8'));
                testResults.passed = results.stats.passes || 0;
                testResults.failed = results.stats.failures || 0;
              } catch (e) {
                console.log('Could not parse test results:', e.message);
              }
            }

            const totalTests = testResults.passed + testResults.failed;
            const successRate = totalTests > 0 ? Math.round((testResults.passed / totalTests) * 100) : 0;

            const body = `## Visual Regression Tests Results

✅ **${testResults.passed} passed** (${successRate}% success rate)
${testResults.failed > 0 ? `❌ **${testResults.failed} failed**` : '✅ **All tests passed!**'}

Visual regression testing ensures your UI changes don't introduce unintended visual differences. The tests compare screenshots across different browsers and devices.

${testResults.failed > 0 ? 'Some tests failed - please review the uploaded artifacts to see the differences.' : 'All visual tests passed! Your changes maintain visual consistency.'}

[View detailed report](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  e2e_a11y:
    needs: [integration]
    runs-on: ubuntu-latest
    if: needs.setup.outputs.profile == 'web-ui'
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - run: make caws:e2e
      - run: make caws:a11y

  perf:
    if: needs.setup.outputs.risk != '3' && (needs.setup.outputs.profile == 'web-ui' || needs.setup.outputs.profile == 'backend-api')
    needs: [integration]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - run: make caws:perf

  provenance_trust:
    needs: [static, unit, mutation, contracts, integration, visual-regression, e2e_a11y, perf]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4
      - run: make caws:bootstrap
      - name: Generate Provenance
        run: tools/caws/provenance > .agent/provenance.json
      - name: Validate Provenance
        run: tools/caws/validate-prov .agent/provenance.json
      - name: Compute Trust Score
        run: tools/caws/gates trust --tier ${{ needs.setup.outputs.risk }} --profile ${{ needs.setup.outputs.profile }}
      - name: Check Spec Delta
        run: tools/caws/gates spec-delta --require-if '.agent/provenance.json.results.spec_changed==true'
